name: Test

on:
  pull_request:
  push:
  schedule:
    - cron: '0 6 * * *'

concurrency:
  group: ${{ github.workflow }}-${{ github.event_name }}-${{ github.ref_name }}
  cancel-in-progress: true

env:
   # Note, that there's "turtle" as well, which is always excluded from running.
   DEFAULT_PYTEST_SELECTION: "integration or usecase or slow or network"
   DEFAULT_PYTEST_SELECTION_OP: "not "  # so it would be "not (integration or usecase)"
   DEFAULT_DATALAD_TESTS_SSH: "1"
   DEFAULT_DATALAD_LOG_ENV: GIT_SSH_COMMAND
   # How/which git-annex we install.  conda's build would be the fastest,
   # but it must not get ahead in PATH to not shadow travis' python
   DEFAULT_ANNEX_INSTALL_SCENARIO: "miniconda=py37_23.1.0-1 --python-match minor --batch git-annex=8.20201007 -m conda"
   BOTO_CONFIG: /tmp/nowhere
   DATALAD_DATASETS_TOPURL: https://datasets-tests.datalad.org

jobs:
  test:
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      matrix:
        include:
          - python-version: '3.7'
            extra-envs: {}

          - python-version: '3.8'
            # Run all tests in a single whoop here
            # We cannot have empty -A selector, so the one which always will be
            # fulfilled
            extra-envs:
              PYTEST_SELECTION: ""
              PYTEST_SELECTION_OP: "not"
              # To test https://github.com/datalad/datalad/pull/4342 fix.
              # From our testing in that PR seems to have no effect, but kept
              # around since should not hurt.
              LC_ALL: ru_RU.UTF-8

          - python-version: '3.9'
            extra-envs:
              PYTEST_SELECTION: ""
              PYTEST_SELECTION_OP: "not"

          # Two matrix runs for "recent python and git-annex with the recent
          # supported by git annex new version of repo" and various extra
          # options/features enabled for git-annex

          - python-version: '3.11'
            extra-envs:
              PYTEST_SELECTION: ""
              PYTEST_SELECTION_OP: "not"
              DATALAD_REPO_VERSION: "10"
              DATALAD_TESTS_GITCONFIG: "\n[annex]\n stalldetection = 1KB/120s\n"
              _DL_ANNEX_INSTALL_SCENARIO: "miniconda --channel conda-forge --python-match minor --batch git-annex -m conda"

          - python-version: '3.11'
            extra-envs:
              PYTEST_SELECTION: ""
              PYTEST_SELECTION_OP: ""
              DATALAD_REPO_VERSION: "10"
              DATALAD_TESTS_GITCONFIG: "\n[annex]\n stalldetection = 1KB/120s\n"
              _DL_ANNEX_INSTALL_SCENARIO: "miniconda --channel conda-forge --python-match minor --batch git-annex -m conda"

          - python-version: '3.7'
            cron-only: true
            extra-envs:
              PYTEST_SELECTION: ""
              PYTEST_SELECTION_OP: "not"

          # Split runs for v6 since a single one is too long now
          - python-version: '3.7'
            extra-envs:
              DATALAD_SSH_MULTIPLEX__CONNECTIONS: "0"
              DATALAD_RUNTIME_PATHSPEC__FROM__FILE: always
              _DL_ANNEX_INSTALL_SCENARIO: "miniconda=py37_23.1.0-1 --python-match minor --batch git-annex=10.20220525 -m conda"

          - python-version: '3.7'
            extra-envs:
              PYTEST_SELECTION_OP: ""
              DATALAD_SSH_MULTIPLEX__CONNECTIONS: "0"
              DATALAD_RUNTIME_PATHSPEC__FROM__FILE: always
              _DL_ANNEX_INSTALL_SCENARIO: "miniconda=py37_23.1.0-1 --python-match minor --batch git-annex=8.20210310 -m conda"
              # To test https://github.com/datalad/datalad/pull/4342 fix in
              # case of no "not" for pytest.  From our testing in that PR seems
              # to have no effect, but kept around since should not hurt.
              LANG: bg_BG.UTF-8

          # Run slow etc tests under a single tricky scenario
          - python-version: '3.7'
            extra-envs:
              PYTEST_SELECTION_OP: ""
              _DL_TMPDIR: "/var/tmp/sym link"
              # And the leading - in filenames for the most challenge
              DATALAD_TESTS_OBSCURE_PREFIX: "-"
              DATALAD_LOG_TRACEBACK: collide  # just a smoke test for now

          # A run loaded with various customizations to smoke test those
          # functionalities
          # Apparently moving symlink outside has different effects on abspath
          # See https://github.com/datalad/datalad/issues/878
          - python-version: '3.7'
            extra-envs:
              # eventually: _DL_TMPDIR: "/var/tmp/sym ссылка"
              _DL_TMPDIR: "/var/tmp/sym link"
              # and obscure the names more a bit
              DATALAD_TESTS_OBSCURE_PREFIX: "-"
              # By default no logs will be output. This one is to test with log
              # output at INFO level
              DATALAD_LOG_LEVEL: INFO
              DATALAD_LOG_TRACEBACK: "1"  # just a smoke test for now
              DATALAD_LOG_VMEM: "1"
              DATALAD_RUNTIME_MAX__BATCHED: "2"
              DATALAD_RUNTIME_MAX__INACTIVE__AGE: "10"

          - python-version: '3.7'
            extra-envs:
              # By default no logs will be output. This one is to test with low
              # level but dumped to /dev/null
              DATALAD_LOG_LEVEL: "2"
              DATALAD_LOG_TARGET: "/dev/null"
              DATALAD_TESTS_PROTOCOLREMOTE: "1"
              DATALAD_TESTS_DATALADREMOTE: "1"
              DATALAD_LOG_CWD: "1"
              DATALAD_LOG_OUTPUTS: "1"
              DATALAD_LOG_ENV: "1"
              DATALAD_LOG_STDIN: "1"
              DATALAD_TESTS_UI_BACKEND: console
              DATALAD_TESTS_OBSCURE_PREFIX: "-"
              DATALAD_SEED: "1"
              GIT_AUTHOR_DATE: "Thu, 07 Apr 2005 22:13:13 +0200"
              GIT_AUTHOR_NAME: blah
              GIT_AUTHOR_EMAIL: committer@example.com
              GIT_COMMITTER_DATE: "Thu, 07 Apr 2005 22:13:13 +0200"
              GIT_COMMITTER_NAME: blah
              GIT_COMMITTER_EMAIL: committer@example.com

          # Test some under NFS mount  (only selected sub-set)
          - python-version: '3.7'
            extra-envs:
              # do not run SSH-based tests due to stall(s)
              # https://github.com/datalad/datalad/pull/4172
              DATALAD_TESTS_SSH: "0"
              _DL_TMPDIR: "/tmp/nfsmount"
              TESTS_TO_PERFORM: "datalad.tests datalad.support"

          # The ones to run only on weekends against master.
          # They will not contribute to coverage etc, but might lead to failed
          # status
          #
          # run with minimal supported git-annex version as defined in
          # AnnexRepo.GIT_ANNEX_MIN_VERSION
          # TODO: ATM we do not have that minimal version as a Debian package
          # in snapshots!

          - python-version: '3.7'
            cron-only: true
            extra-envs:
              _DL_ANNEX_INSTALL_SCENARIO: "miniconda=py37_23.1.0-1 --python-match minor --batch git-annex=8.20200309 -m conda"

          # Run with git's master branch rather the default one on the system.
          - python-version: '3.7'
            cron-only: true
            upstream-git: true
            extra-envs:
              DATALAD_USE_DEFAULT_GIT: "1"

          # Run with our reported minimum Git version.
          - python-version: '3.7'
            cron-only: true
            minimum-git: true
            extra-envs:
              DATALAD_USE_DEFAULT_GIT: "1"

          - python-version: '3.7'
            cron-only: true
            extra-envs:
              # to test operation under root since also would consider FS
              # "crippled" due to ability to rewrite R/O files
              PYTEST_WRAPPER: "sudo -E"
              # no key authentication for root:
              DATALAD_TESTS_SSH: "0"

          - python-version: '3.7'
            cron-only: true
            extra-envs:
              DATALAD_TESTS_NONETWORK: "1"
              # must operate nicely with those env variables set
              http_proxy: ""
              https_proxy: ""

          # Test under NFS mount  (full, only in master)
          - python-version: '3.7'
            cron-only: true
            allow-failure: true
            extra-envs:
              _DL_TMPDIR: "/tmp/nfsmount"

          # Causes complete laptop or travis instance crash atm, but survives
          # in a docker need to figure it out (looks like some PID explosion)
          # We would need to migrate to boto3 to test it fully, but SSH should
          # work
          #- python-version: '3.7'
          #  extra-envs:
          #    DATALAD_TESTS_SSH: "1"
          #    UNSET_S3_SECRETS: "1"

    env: ${{ matrix.extra-envs }}
    if: "!matrix.cron-only || github.event_name == 'schedule'"
    continue-on-error: ${{ matrix.allow-failure }}
    steps:
      - name: Check out repository
        uses: actions/checkout@v4
        with:
          # Do full clone (~10 extra seconds) to fetch all tags.
          # Otherwise we might be missing the tags for maint PRs
          # whenever those maint releases were not yet merged into master.
          fetch-depth: 0

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}

      - name: Show git describe output to ensure that we did fetch all the tags
        run: git describe

      # Just in case we need to check if nfs is there etc
      - run: sudo lsmod

      - name: Install dependencies
        run: |
          # The ultimate one-liner setup for NeuroDebian repository
          bash <(wget -q -O- http://neuro.debian.net/_files/neurodebian-travis.sh)
          sudo apt-get update -qq
          sudo apt-get install eatmydata  # to speedup some installations
          tools/ci/prep-travis-forssh.sh
          tools/ci/debians_disable_outdated_ssl_cert
          # Install various basic dependencies
          sudo eatmydata apt-get install zip pandoc p7zip-full
          # needed for tests of patool compression fall-back solution
          sudo eatmydata apt-get install xz-utils
          sudo eatmydata apt-get install shunit2

      - name: Configure _DL_TMPDIR before installing git-annex
        run: |
          if [[ "${_DL_TMPDIR:-}" =~ .*/sym\ link ]]
          then echo "Symlinking $_DL_TMPDIR"
               ln -s /tmp "$_DL_TMPDIR"
          fi

          if [[ "${_DL_TMPDIR:-}" =~ .*/d\ i\ r ]]
          then echo "mkdir $_DL_TMPDIR"
               mkdir -p "$_DL_TMPDIR"
          fi

          if [[ "${_DL_TMPDIR:-}" =~ .*/nfsmount ]]
          then echo "mkdir $_DL_TMPDIR"
               mkdir -p "$_DL_TMPDIR" "${_DL_TMPDIR}_"
               echo "/tmp/nfsmount_ localhost(rw)" | sudo bash -c 'cat - > /etc/exports'
               sudo apt-get install -y nfs-kernel-server
               sudo exportfs -a
               sudo mount -t nfs localhost:/tmp/nfsmount_ /tmp/nfsmount
          fi

      - name: Install custom Git from upstream
        if: matrix.upstream-git
        run: |
          source tools/ci/install-upstream-git.sh
          echo PATH="$PATH" >> "$GITHUB_ENV"

      - name: Install minimum Git
        if: matrix.minimum-git
        run: |
          tools/ci/install-minimum-git.sh
          echo PATH="$PWD/git-src/bin-wrappers/:$PATH" >> "$GITHUB_ENV"

      - name: Install git-annex
        run: |
          pip install datalad-installer
          eval datalad-installer --sudo ok -E new.env ${_DL_ANNEX_INSTALL_SCENARIO:-$DEFAULT_ANNEX_INSTALL_SCENARIO}
          cat new.env >> "$GITHUB_ENV"

      - name: Install Python dependencies
        run: |
          pip install --upgrade pip
          pip install codecov
          pip install -r requirements-devel.txt

      - name: Configure Git
        run: |
          git config --global user.email "test@github.land"
          git config --global user.name "GitHub Almighty"
          # We do `sudo pip install` below, and versioneer needs to run git.
          # Recent git needs to be made certain it is safe to do
          sudo git config --global --add safe.directory $PWD

      - name: Configure sudoers
        # So we could test under sudo -E with PATH pointing to installed
        # location
        run: sudo sed -i -e 's/^Defaults.*secure_path.*$//' /etc/sudoers

      # TODO: remove - should not be needed
      - name: Git-annex workaround for NFS mounts
        run: |
          if [[ "${_DL_TMPDIR:-}" =~ .*/nfsmount ]]
          then sudo git config --system annex.pidlock true
          fi

      # Now it should be safe to point TMPDIR to a "tricky" setup just for the
      # purpose of testing
      - name: Point TMPDIR to "tricky" setup
        run: |
          if [ -n "${_DL_TMPDIR:-}" ]
          then echo TMPDIR="${_DL_TMPDIR}" >> "$GITHUB_ENV"
          fi

      - name: Test installation for user
        run: sudo pip install --user .

      - name: Report WTF information using system-wide installed version
        run: datalad wtf

      - name: Run tests
        run: |
          : "${PYTEST_SELECTION:=$DEFAULT_PYTEST_SELECTION}"
          : "${PYTEST_SELECTION_OP:=$DEFAULT_PYTEST_SELECTION_OP}"
          : "${DATALAD_TESTS_SSH:=$DEFAULT_DATALAD_TESTS_SSH}"
          : "${DATALAD_LOG_ENV:=$DEFAULT_DATALAD_LOG_ENV}"

          PYTEST_OPTS=( -v )
          # If we requested to run only not slow (typically <10sec) tests, fail
          # if a test takes 3x more than that - it needs to get @slow or
          # @turtle annotation
          if echo "$PYTEST_SELECTION_OP($PYTEST_SELECTION)" | grep -q "^not.*slow"
          then
            PYTEST_OPTS=( "${PYTEST_OPTS[@]}" --doctest-modules --durations=0 --durations-min=5 --fail-slow 60 )
            export DATALAD_TESTS_SETUP_TESTREPOS=1
          fi

          mkdir -p __testhome__
          cd __testhome__
          # Note: adding --log-cli-level=INFO would result in
          # DATALAD_LOG_TARGET=/dev/null being not in effect, dumping too many
          # logs.
          set -x
          http_proxy=
          PATH=$PWD/../tools/coverage-bin:$PATH
          $PYTEST_WRAPPER python \
            -m pytest "${PYTEST_OPTS[@]}" \
            -c ../tox.ini \
            -n 2 \
            -m "${PYTEST_SELECTION:+$PYTEST_SELECTION_OP($PYTEST_SELECTION) and }not(turtle)" \
            --doctest-modules \
            --cov=datalad \
            --cov-report=xml \
            --pyargs ${TESTS_TO_PERFORM:-datalad}

      # Makes it only more difficult to comprehend the failing output.  Enable
      # only when necessary for a particular debugging.
      - name: Dump debug info
        #if: "failure()"  # Enabled
        if: "failure() && false"  # Disabled
        run: |
          if [ ! -z "$DATALAD_TESTS_NONETWORK" ]
          then sudo route add -net 0.0.0.0 netmask 0.0.0.0 dev lo
          fi

          DATALAD_LOG_LEVEL=DEBUG \
            $PYTEST_WRAPPER `which pytest` \
            -s -v --doctest-modules --cov datalad --log-cli-level=DEBUG

          if [ ! -z "$DATALAD_TESTS_NONETWORK" ]
          then sudo route del -net 0.0.0.0 netmask 0.0.0.0 dev lo
          fi

      # cron jobs test more and then PRs will be falling behind since they
      # would not trigger some codepaths.  So submit coverage only from
      # non-cron jobs, but report for all

      - name: Report coverage
        run: python -m coverage report
        working-directory: __testhome__

      - name: Upload coverage to Codecov
        if: github.event_name == 'schedule'
        uses: codecov/codecov-action@v4
        with:
          directory: __testhome__
          fail_ci_if_error: false
          token: ${{ secrets.CODECOV_TOKEN }}

# vim:set et sts=2:
